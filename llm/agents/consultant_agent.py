import logging
import sqlite3
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer

from llm.client import llm_client
from llm.prompts.consultant_prompts import get_consultant_prompt

logger = logging.getLogger(__name__)

class RAGConsultantAgent:
    """
    –ê–≥–µ–Ω—Ç-–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å –ø–æ–∏—Å–∫–æ–º —á–µ—Ä–µ–∑ –≤–∞—à—É SQLite –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É —Å VSS
    """
    
    def __init__(self, db_path: str = 'mipti_dormitory_db.db'):
        self.name = "–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å RAG"
        self.db_path = db_path
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.conversation_history: List[Dict] = []
        
        logger.info(f"RAGConsultantAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –±–∞–∑–æ–π: {db_path}")
    
    def _get_connection(self) -> sqlite3.Connection:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # –í–∫–ª—é—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è VSS
            conn.enable_load_extension(True)
            try:
                conn.load_extension("vector")
                conn.load_extension("vss0")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è VSS: {e}")
            
            return conn
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    async def ask_question(self, question: str, user_id: str = None, limit: int = 5) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ —Å RAG —á–µ—Ä–µ–∑ –≤–∞—à—É –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            Dict —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ
            relevant_docs = await self._search_in_database(question, limit=limit)
            
            # 2. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            context = self._format_context(relevant_docs)
            
            # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            answer = await self._generate_rag_response(question, context)
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            if user_id:
                self._save_to_history(user_id, question, answer, relevant_docs)
            
            # 5. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            return {
                "answer": answer,
                "sources": relevant_docs,
                "context_used": bool(relevant_docs),
                "sources_count": len(relevant_docs),
                "has_context": context != "–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ RAG –∞–≥–µ–Ω—Ç–µ: {e}")
            return {
                "answer": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                "sources": [],
                "context_used": False,
                "error": str(e)
            }
    
    async def _search_in_database(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ —á–µ—Ä–µ–∑ VSS
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            List —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞
            search_vector = self.model.encode([query])[0].tolist()
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏ —á–µ—Ä–µ–∑ VSS
            cursor.execute('''
                SELECT 
                    t.id, 
                    t.text, 
                    t.category,
                    t.tags,
                    vss_distance AS similarity
                FROM dormitory_vectors 
                JOIN dormitory_info t ON t.id = dormitory_vectors.rowid
                WHERE vss_search(vector, ?)
                LIMIT ?
            ''', (search_vector, limit))
            
            results = cursor.fetchall()
            conn.close()
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            formatted_results = []
            for row in results:
                doc_id, text, category, tags, similarity = row
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ —Å—Ö–æ–∂–µ—Å—Ç—å (—á–µ–º –º–µ–Ω—å—à–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ - —Ç–µ–º –±–æ–ª—å—à–µ —Å—Ö–æ–∂–µ—Å—Ç—å)
                similarity_score = 1.0 / (1.0 + similarity) if similarity > 0 else 1.0
                
                formatted_results.append({
                    'id': doc_id,
                    'content': text,
                    'source': '–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ–±—â–µ–∂–∏—Ç–∏—è –ú–ò–§–ò',
                    'category': category,
                    'tags': tags,
                    'similarity': similarity_score,
                    'distance': similarity
                })
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(formatted_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
            return formatted_results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ: {e}")
            return []
    
    def _format_context(self, documents: List[Dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        if not documents:
            return "–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        
        context_parts = ["üìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –æ–±—â–µ–∂–∏—Ç–∏—è –ú–ò–§–ò:"]
        
        for i, doc in enumerate(documents, 1):
            category = doc.get('category', '–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è')
            content = doc.get('content', '')
            similarity = doc.get('similarity', 0)
            
            context_parts.append(
                f"\n--- –ó–∞–ø–∏—Å—å {i}: {category} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.2f}) ---\n"
                f"{content}"
            )
        
        return "\n".join(context_parts)
    
    async def _generate_rag_response(self, question: str, context: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        prompt = get_consultant_prompt(context, question)
        
        try:
            response = await llm_client.generate_response(
                prompt, 
                temperature=0.3,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                max_tokens=600
            )
            return response.strip()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            # Fallback –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if context and "–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏" not in context:
                return (
                    "–ù–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –æ–±—â–µ–∂–∏—Ç–∏—è –ú–ò–§–ò:\n\n"
                    f"{context}\n\n"
                    "–î–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–æ–º–µ–Ω–¥–∞–Ω—Ç—É –≤–∞—à–µ–≥–æ –æ–±—â–µ–∂–∏—Ç–∏—è."
                )
            else:
                return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –æ–±—â–µ–∂–∏—Ç–∏—è –ú–ò–§–ò –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –†–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–æ–º–µ–Ω–¥–∞–Ω—Ç—É –ª–∏—á–Ω–æ –∏–ª–∏ –≤ —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–π –æ—Ñ–∏—Å."
    
    def _save_to_history(self, user_id: str, question: str, answer: str, sources: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é"""
        conversation = {
            "user_id": user_id,
            "question": question,
            "answer": answer,
            "sources": [f"{s.get('category', '')}: {s.get('content', '')[:50]}..." for s in sources],
            "sources_count": len(sources),
            "timestamp": self._get_current_timestamp()
        }
        self.conversation_history.append(conversation)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 100 –¥–∏–∞–ª–æ–≥–∞–º–∏
        if len(self.conversation_history) > 100:
            self.conversation_history = self.conversation_history[-100:]
    
    def get_conversation_history(self, user_id: str = None) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤"""
        if user_id:
            return [conv for conv in self.conversation_history if conv['user_id'] == user_id]
        return self.conversation_history
    
    def _get_current_timestamp(self) -> str:
        """–¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    async def add_knowledge(self, text: str, category: str = "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", tags: str = "–æ–±—â–µ–∂–∏—Ç–∏–µ, –ú–ò–§–ò") -> int:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            tags: –¢–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
        """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            vector = self.model.encode([text])[0].tolist()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç
            cursor.execute(
                'INSERT INTO dormitory_info (text, category, tags) VALUES (?, ?, ?)',
                (text, category, tags)
            )
            text_id = cursor.lastrowid
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä
            conn.execute(
                'INSERT INTO dormitory_vectors(rowid, vector) VALUES (?, ?)',
                (text_id, vector)
            )
            
            conn.commit()
            conn.close()
            
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–ø–∏—Å—å –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (ID: {text_id})")
            return text_id
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}")
            raise
    
    def get_database_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            cursor.execute('SELECT COUNT(*) FROM dormitory_info')
            total_records = cursor.fetchone()[0]
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            cursor.execute('SELECT category, COUNT(*) FROM dormitory_info GROUP BY category')
            categories = cursor.fetchall()
            
            conn.close()
            
            return {
                "total_records": total_records,
                "categories": dict(categories),
                "database_path": self.db_path
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"error": str(e)}
